services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: orbicheck
    ports:
      - "5432:5432"
    volumes:
      - "pg_data:/var/lib/postgresql/data"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  valkey:
    image: valkey/valkey:7.2
    ports:
      - "6379:6379"
    command: ["--appendonly", "yes"]
    healthcheck:
      test: ["CMD", "valkey-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  dashboard:
    image: node:18
    working_dir: /app
    volumes:
      - ../../:/app
    command: sh -c "npm install -g pnpm && pnpm install && cd apps/dashboard && pnpm run dev --host 0.0.0.0"
    ports:
      - "5173:5173"
    environment:
      - CI=true
    depends_on:
      - api

  caddy:
      build: ./caddy
      ports:
        - "8081:80"
      volumes:
        - ./dev.Caddyfile:/etc/caddy/Caddyfile
        - ../../apps/site:/usr/share/caddy/site
        - caddy_data:/data
        - caddy_config:/config
      depends_on:
        api:
          condition: service_healthy
        postgres:
          condition: service_healthy
        valkey:
          condition: service_healthy

  api:
    build:
      context: ../../
      dockerfile: apps/api/Dockerfile
    environment:
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/orbicheck
      REDIS_URL: redis://valkey:6379
      S3_ENDPOINT: http://minio:9000
      S3_ACCESS_KEY: minioadmin
      S3_SECRET_KEY: minioadmin
      S3_BUCKET: orbicheck
      RATE_LIMIT_COUNT: 30000
      LOG_LEVEL: info
      VIES_DOWN: "true"
      JWT_SECRET: dev-jwt-secret-key
      INFISICAL_SITE_URL: http://infisical:8080
      INFISICAL_ENVIRONMENT: dev
      INFISICAL_PROJECT_ID: local-project
      INFISICAL_SERVICE_TOKEN: local-dev-token
    depends_on:
      postgres:
        condition: service_healthy
      valkey:
        condition: service_healthy
      minio:
        condition: service_healthy
      infisical:
        condition: service_started
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  prom:
    image: prom/prometheus:latest
    volumes:
      - ../prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ../grafana/provisioning:/etc/grafana/provisioning

  loki:
    image: grafana/loki:2.9.0
    command: -config.file=/etc/loki/local-config.yaml
    ports:
      - "3100:3100"
    volumes:
      - ../loki/local-config.yaml:/etc/loki/local-config.yaml
      - loki_data:/loki

  promtail:
    image: grafana/promtail:2.9.0
    command: -config.file=/etc/promtail/config.yml
    volumes:
      - ../promtail/config.yml:/etc/promtail/config.yml
    depends_on:
      - loki


  statping:
    image: statping/statping:latest
    ports:
      - "8082:80"
    volumes:
      - statping_data:/app
    environment:
      - DATABASE=sqlite
    depends_on:
      - api

  uptime-kuma:
    image: louislam/uptime-kuma:1
    ports:
      - "3001:3001"
    volumes:
      - uptime_kuma_data:/app/data
    restart: always
    depends_on:
      - caddy


  infisical-backend:
    container_name: infisical-backend
    restart: unless-stopped
    depends_on:
      infisical-db:
        condition: service_healthy
      infisical-redis:
        condition: service_started
    image: infisical/infisical:v0.150.0
    pull_policy: always
    env_file: .env.infisical
    ports:
      - "8085:8080"
    environment:
      - NODE_ENV=production
    networks:
      - infisical_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/status"] 
      interval: 30s
      timeout: 10s
      retries: 5

  infisical-setup:
    image: alpine:latest
    command: ["sh", "/setup.sh"]
    volumes:
      - ./infisical-setup.sh:/setup.sh
      - infisical_credentials:/tmp
    depends_on:
      infisical-backend:
        condition: service_healthy
      infisical-db:
        condition: service_healthy
      infisical-redis:
        condition: service_started
    networks:
      - infisical_net
    environment:
      - INFISICAL_RESET_DB=true
    profiles:
      - setup

  infisical-redis:
    image: redis
    container_name: infisical-redis
    env_file: .env.infisical
    restart: always
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    networks:
      - infisical_net
    volumes:
      - infisical_redis_data:/data

  infisical-db:
    container_name: infisical-db
    image: postgres:14-alpine
    restart: always
    environment:
      POSTGRES_PASSWORD: infisical
      POSTGRES_USER: infisical
      POSTGRES_DB: infisical
    volumes:
      - infisical_pg_data:/var/lib/postgresql/data
    networks:
      - infisical_net
    healthcheck:
      test: "pg_isready --username=$${POSTGRES_USER} && psql --username=$${POSTGRES_USER} --list"
      interval: 5s
      timeout: 10s
      retries: 10

volumes:
  pg_data: {}
  minio_data: {}
  grafana_data: {}
  loki_data: {}
  caddy_data: {}
  caddy_config: {}
  statping_data: {}
  uptime_kuma_data: {}
  infisical_pg_data:
    driver: local
  infisical_redis_data:
    driver: local
  infisical_credentials:
    driver: local

networks:
  infisical_net: